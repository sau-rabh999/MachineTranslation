{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_Translation_LSTM(seq2seq_network).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sau-rabh999/MachineTranslation/blob/main/Machine_Translation_LSTM(seq2seq_network).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BrkTGDeLxvU",
        "outputId": "13fe68de-dac5-4181-f2ba-4a607bf3250e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD0e8c6qwsKl"
      },
      "source": [
        "Using seq2seq model to perform our task of machine translation. This involves translating from english language to hindi language"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krxv6AKDw-_H"
      },
      "source": [
        "**Sacrebleu is used as an accuracy parameter which gives us the accuracy of our model prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zQvoibJqmeR",
        "outputId": "538fbb5c-c27b-4dc5-d243-c80637532460"
      },
      "source": [
        "!pip install sacrebleu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\r\u001b[K     |██████                          | 10kB 11.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 20kB 16.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 30kB 11.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 40kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.2MB/s \n",
            "\u001b[?25hCollecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Installing collected packages: portalocker, sacrebleu\n",
            "Successfully installed portalocker-2.0.0 sacrebleu-1.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bsfN4sEBxzk"
      },
      "source": [
        "Importing Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc1H_aotRLk4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "import math\n",
        "import os\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sacrebleu import sentence_bleu\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zROhHyK8B1G9"
      },
      "source": [
        "Reading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Tc1vMcIqSjCh",
        "outputId": "a1e21924-c4b8-48f5-977b-735f67d95552"
      },
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Machine Translation/hin.txt\", sep='\\t', header=None, names=[\"english_sentence\",\"hindi_sentence\",\"path\"])\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>वाह!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Help!</td>\n",
              "      <td>बचाओ!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>उछलो.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>कूदो.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>छलांग.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>नमस्ते।</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>नमस्कार।</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Cheers!</td>\n",
              "      <td>वाह-वाह!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Cheers!</td>\n",
              "      <td>चियर्स!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Got it?</td>\n",
              "      <td>समझे कि नहीं?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  english_sentence  ...                                               path\n",
              "0             Wow!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
              "1            Help!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n",
              "2            Jump.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #6...\n",
              "3            Jump.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #6...\n",
              "4            Jump.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #6...\n",
              "5           Hello!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "6           Hello!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "7          Cheers!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n",
              "8          Cheers!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n",
              "9          Got it?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ODsrCR1S01j",
        "outputId": "70d138d5-b4ba-4ff8-a47a-34f2b9bb7720"
      },
      "source": [
        "df= df.drop(columns=['path'])\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2774, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AlNjPJ2S5Sk",
        "outputId": "07af1268-21e0-4486-e7aa-530875095fd7"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "english_sentence    0\n",
              "hindi_sentence      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aaU7CmdB66v"
      },
      "source": [
        "Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i23vKEKzTTHV"
      },
      "source": [
        "df['english_sentence']=df['english_sentence'].apply(lambda x: x.lower())\n",
        "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: x.lower())\n",
        "df['english_sentence']=df['english_sentence'].apply(lambda x: x.strip())\n",
        "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: x.strip())\n",
        "df['english_sentence']=df['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "df['english_sentence']=df['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in string.punctuation))\n",
        "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in string.punctuation))\n",
        "df['english_sentence']=df['english_sentence'].str.replace('\\d+', '')\n",
        "df['hindi_sentence']=df['hindi_sentence'].str.replace('\\d+', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYvXhuHgB-Ef"
      },
      "source": [
        "Marking start and end  in the target language data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPOqBesLTXGK"
      },
      "source": [
        "start = '<s> '\n",
        "end = ' </s>'\n",
        "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x : start + x + end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9KeRmT2BMmOQ",
        "outputId": "12f52c14-a0ac-42cb-8a1b-854b1ebe3da4"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wow</td>\n",
              "      <td>&lt;s&gt; वाह &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>help</td>\n",
              "      <td>&lt;s&gt; बचाओ &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>jump</td>\n",
              "      <td>&lt;s&gt; उछलो &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jump</td>\n",
              "      <td>&lt;s&gt; कूदो &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jump</td>\n",
              "      <td>&lt;s&gt; छलांग &lt;/s&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  english_sentence  hindi_sentence\n",
              "0              wow    <s> वाह </s>\n",
              "1             help   <s> बचाओ </s>\n",
              "2             jump   <s> उछलो </s>\n",
              "3             jump   <s> कूदो </s>\n",
              "4             jump  <s> छलांग </s>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yILxiczHTbON"
      },
      "source": [
        "english_vocab = {}\n",
        "for i in df.english_sentence:\n",
        "  for word in i.split():\n",
        "    if word not in english_vocab:\n",
        "      english_vocab[word] = 1\n",
        "    else:\n",
        "      english_vocab[word]+=1\n",
        "\n",
        "hindi_vocab={}\n",
        "for j in df.hindi_sentence:\n",
        "  for a in j.split():\n",
        "    if a not in hindi_vocab:\n",
        "      hindi_vocab[a] = 1\n",
        "    else:\n",
        "      hindi_vocab[a]+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqS1PoniiXc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c0b20f-3cc6-48c1-d62d-c01551b51c26"
      },
      "source": [
        "num_encoder_tokens=len(english_vocab.keys())\n",
        "num_decoder_token=len(hindi_vocab.keys())\n",
        "length = []\n",
        "for i in df.english_sentence:\n",
        "  length.append(len(i.split(' ')))\n",
        "max_input_length = max(length)\n",
        "print('max_input_length: ', max_input_length)\n",
        "length = []\n",
        "for i in df.hindi_sentence:\n",
        "  length.append(len(i.split(' ')))\n",
        "max_output_length = max(length)\n",
        "print('max_output_length: ', max_output_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_input_length:  22\n",
            "max_output_length:  27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOuASQWfj3i7"
      },
      "source": [
        "input_words = sorted(list(english_vocab.keys()))\n",
        "target_words = sorted(list(hindi_vocab.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UKqxgw8EDM_"
      },
      "source": [
        "input_token_index = dict([(word, i) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i) for i, word in enumerate(target_words)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zPpJK6HicuE"
      },
      "source": [
        "encoder_input_data = np.zeros((len(df.english_sentence), max_input_length), dtype='float32')\n",
        "decoder_input_data = np.zeros((len(df.hindi_sentence), max_output_length), dtype='float32')\n",
        "decoder_target_data = np.zeros((len(df.hindi_sentence), max_output_length, num_decoder_token))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egq4ccizjASN"
      },
      "source": [
        "for i,(input_text, output_text) in enumerate(zip(df.english_sentence, df.hindi_sentence)):\n",
        "  for t, word in enumerate(input_text.split()):\n",
        "    encoder_input_data[i,t] = input_token_index[word]\n",
        "  for t,word in enumerate(output_text.split()):\n",
        "    decoder_input_data[i,t] = target_token_index[word]\n",
        "    if t > 0:\n",
        "      decoder_target_data[i,t-1,target_token_index[word]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgXoNbou-JOO"
      },
      "source": [
        "latent_dim=300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f67xU15wyc9N"
      },
      "source": [
        "Embedding convert wored token index to word vector                 \n",
        "LSTM gives 3 outputs:\n",
        "\n",
        "    i) output for next layer\n",
        "    ii) cell memory\n",
        "    iii) hidden state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfkhNY3SzJv6"
      },
      "source": [
        "But we need only the encoder states i.e, the cell memory value and hidden state value to give it as the input to the decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JpMDHn37n2y"
      },
      "source": [
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J2G9TZi-OQF"
      },
      "source": [
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_token, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_token, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaHm67He9SFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea76a36e-7dd6-483f-d634-ec92a6a8dd24"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 300)    702900      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    890700      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 300), (None, 721200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 2969)   893669      lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 3,929,669\n",
            "Trainable params: 3,929,669\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o_qSIbKCUY-"
      },
      "source": [
        "Fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-Nb-ERncN-Q",
        "outputId": "9324bae2-eb97-4fbf-92a7-aa4389abdbd6"
      },
      "source": [
        " model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=100, epochs=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "28/28 [==============================] - 31s 852ms/step - loss: 1.8057 - accuracy: 0.1345\n",
            "Epoch 2/25\n",
            "28/28 [==============================] - 24s 858ms/step - loss: 1.6054 - accuracy: 0.1511\n",
            "Epoch 3/25\n",
            "28/28 [==============================] - 24s 851ms/step - loss: 1.5482 - accuracy: 0.1547\n",
            "Epoch 4/25\n",
            "28/28 [==============================] - 24s 854ms/step - loss: 1.5055 - accuracy: 0.1633\n",
            "Epoch 5/25\n",
            "28/28 [==============================] - 24s 856ms/step - loss: 1.4649 - accuracy: 0.1758\n",
            "Epoch 6/25\n",
            "28/28 [==============================] - 24s 855ms/step - loss: 1.4210 - accuracy: 0.1911\n",
            "Epoch 7/25\n",
            "28/28 [==============================] - 24s 854ms/step - loss: 1.3785 - accuracy: 0.2025\n",
            "Epoch 8/25\n",
            "28/28 [==============================] - 24s 857ms/step - loss: 1.3378 - accuracy: 0.2127\n",
            "Epoch 9/25\n",
            "28/28 [==============================] - 24s 857ms/step - loss: 1.2984 - accuracy: 0.2225\n",
            "Epoch 10/25\n",
            "28/28 [==============================] - 24s 860ms/step - loss: 1.2610 - accuracy: 0.2337\n",
            "Epoch 11/25\n",
            "28/28 [==============================] - 24s 865ms/step - loss: 1.2227 - accuracy: 0.2462\n",
            "Epoch 12/25\n",
            "28/28 [==============================] - 24s 864ms/step - loss: 1.1857 - accuracy: 0.2616\n",
            "Epoch 13/25\n",
            "28/28 [==============================] - 24s 858ms/step - loss: 1.1491 - accuracy: 0.2751\n",
            "Epoch 14/25\n",
            "28/28 [==============================] - 24s 861ms/step - loss: 1.1133 - accuracy: 0.2889\n",
            "Epoch 15/25\n",
            "28/28 [==============================] - 24s 857ms/step - loss: 1.0787 - accuracy: 0.3000\n",
            "Epoch 16/25\n",
            "28/28 [==============================] - 24s 859ms/step - loss: 1.0458 - accuracy: 0.3095\n",
            "Epoch 17/25\n",
            "28/28 [==============================] - 24s 863ms/step - loss: 1.0109 - accuracy: 0.3253\n",
            "Epoch 18/25\n",
            "28/28 [==============================] - 24s 862ms/step - loss: 0.9783 - accuracy: 0.3392\n",
            "Epoch 19/25\n",
            "28/28 [==============================] - 24s 862ms/step - loss: 0.9457 - accuracy: 0.3546\n",
            "Epoch 20/25\n",
            "28/28 [==============================] - 24s 865ms/step - loss: 0.9130 - accuracy: 0.3665\n",
            "Epoch 21/25\n",
            "28/28 [==============================] - 24s 869ms/step - loss: 0.8819 - accuracy: 0.3806\n",
            "Epoch 22/25\n",
            "28/28 [==============================] - 24s 862ms/step - loss: 0.8501 - accuracy: 0.4009\n",
            "Epoch 23/25\n",
            "28/28 [==============================] - 24s 858ms/step - loss: 0.8196 - accuracy: 0.4167\n",
            "Epoch 24/25\n",
            "28/28 [==============================] - 24s 859ms/step - loss: 0.7906 - accuracy: 0.4302\n",
            "Epoch 25/25\n",
            "28/28 [==============================] - 24s 858ms/step - loss: 0.7584 - accuracy: 0.4516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f94ed5e1fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-JTMRw_CX79"
      },
      "source": [
        "Encoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXHnMjgYmUGp",
        "outputId": "0de695c1-3e73-489a-d461-01bb12aceaa3"
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "encoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, None, 300)         702900    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  [(None, 300), (None, 300) 721200    \n",
            "=================================================================\n",
            "Total params: 1,424,100\n",
            "Trainable params: 1,424,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4KKOrxFCXcN"
      },
      "source": [
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggBAMKeXyD88"
      },
      "source": [
        "Decoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_s1fZTfoBcp",
        "outputId": "d5fc462d-ba44-429e-80c0-2bf9e28da1f5"
      },
      "source": [
        "decoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    890700      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 300)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 300)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_1[1][0]                \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 2969)   893669      lstm_1[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 2,505,569\n",
            "Trainable params: 2,505,569\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhmzg8fSnB9u"
      },
      "source": [
        "reverse_input_char_index = dict((i,char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i,char) for char, i in target_token_index.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbwlWVS0Cxd4"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = target_token_index['<s>']\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "        if (sampled_char == '</s>' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsrEprJDyMIH"
      },
      "source": [
        "Finding the accuracy of our model using bleu score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnQAznguL2Ml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf7cfb20-fd67-4a3c-e66d-28bc6624db25"
      },
      "source": [
        "k=2001\n",
        "english =df.english_sentence[k:k+1].values[0]\n",
        "actual = df.hindi_sentence[k:k+1].values[0]\n",
        "predicted = decode_sequence(encoder_input_data[k:k+1])\n",
        "print(\"The actual english sentence is:\",english)\n",
        "print(\"The actual hindi sentence is:\",actual)\n",
        "print(\"The predicted hindi sentence is:\",predicted)\n",
        "print(\"The BLEU score is :\",sentence_bleu(predicted,[actual]).score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The actual english sentence is: the doctor advised him not to smoke\n",
            "The actual hindi sentence is: <s> डॉक्टर ने उसे सिगरेट न पीने की सलह दी। </s>\n",
            "The predicted hindi sentence is:  डॉक्टर ने अपने बाल पीने की कोशिश करी। </s>\n",
            "The BLEU score is : 20.52596383056271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7QsiKm6PcU8",
        "outputId": "2a256981-443e-440f-91e6-7838e900e846"
      },
      "source": [
        "k=1301\n",
        "english =df.english_sentence[k:k+1].values[0]\n",
        "actual = df.hindi_sentence[k:k+1].values[0]\n",
        "predicted = decode_sequence(encoder_input_data[k:k+1])\n",
        "print(\"The actual english sentence is:\",english)\n",
        "print(\"The actual hindi sentence is:\",actual)\n",
        "print(\"The predicted hindi sentence is:\",predicted)\n",
        "print(\"The BLEU score is :\",sentence_bleu(predicted,[actual]).score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The actual english sentence is: you are not coming are you\n",
            "The actual hindi sentence is: <s> तुम नहीं आ रहे हो ना </s>\n",
            "The predicted hindi sentence is:  तुम तुम क्यों नहीं कर सकते। </s>\n",
            "The BLEU score is : 21.53672420052281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO_CKkDV59yC",
        "outputId": "8496d4a6-525e-498f-9a6e-f5161a1bd237"
      },
      "source": [
        "k=1\n",
        "english =df.english_sentence[k:k+1].values[0]\n",
        "actual = df.hindi_sentence[k:k+1].values[0]\n",
        "predicted = decode_sequence(encoder_input_data[k:k+1])\n",
        "print(\"The actual english sentence is:\",english)\n",
        "print(\"The actual hindi sentence is:\",actual)\n",
        "print(\"The predicted hindi sentence is:\",predicted)\n",
        "print(\"The BLEU score is :\",sentence_bleu(predicted,[actual]).score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The actual english sentence is: help\n",
            "The actual hindi sentence is: <s> बचाओ </s>\n",
            "The predicted hindi sentence is:  मैं मत करो। </s>\n",
            "The BLEU score is : 35.64026463354184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AV_jm8Y26jNL",
        "outputId": "880dcf7b-0740-4369-c606-288bf4ab72ec"
      },
      "source": [
        "test_sentence = 'i am fine'\n",
        "encoder_test_data = np.zeros((len(df.english_sentence), max_input_length), dtype='float32')\n",
        "for t, word in enumerate(test_sentence.split()):\n",
        "    encoder_test_data[1,t] = input_token_index[word]\n",
        "decode_sequence(encoder_test_data[1:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' मैं थक गया हूँ। </s>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    }
  ]
}